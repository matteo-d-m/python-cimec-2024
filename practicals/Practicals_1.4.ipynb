{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fad0eb81",
   "metadata": {},
   "source": [
    "# Practicals for lecture 1.4\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/vigji/python-cimec/blob/main/practicals/Practicals_1.4.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fb86a8",
   "metadata": {},
   "source": [
    "#### 1.4.0 Organize a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f2f3e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Let's have a look into how to organize data in a dataframe.\n",
    "\n",
    "# Use the following function that generates results for many subjects on\n",
    "# an experiment with experimental trials of different difficulty levels.\n",
    "\n",
    "def get_experiment_block_data(n_subjects=50, difficulty_levels=(1, 2, 3, 4, 5), n_repetitions=50):\n",
    "    \"\"\"Generate a dataframe with results from an experiment with experimental blocks.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_reps : int\n",
    "        Number of experimental blocks.\n",
    "    n_subjects : int\n",
    "        Number of subjects.\n",
    "    difficulty_levels : tuple\n",
    "        Difficulty levels of the experimental blocks.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        A dictionary with the results of the experiment for each subject.\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    np.random.seed(42)\n",
    "    subject_dict = dict()\n",
    "    for subject in range(n_subjects):\n",
    "        subject_ability = np.random.randint(1, 6)\n",
    "        difficulty_level_arr = np.random.choice(difficulty_levels, size=n_repetitions)\n",
    "        rt = np.random.normal(1000, 100, size=n_repetitions) * difficulty_level_arr / subject_ability\n",
    "        error = np.random.uniform(0, 1000*difficulty_level_arr / subject_ability, size=n_repetitions)\n",
    "\n",
    "        subject_dict[f\"subject_{subject}\"] = dict(\n",
    "            difficulty_level=difficulty_level_arr,\n",
    "            rt=rt,\n",
    "            error=error,\n",
    "        )\n",
    "\n",
    "    return subject_dict\n",
    "\n",
    "\n",
    "# Run the function to generate the data dictionary.\n",
    "data = get_experiment_block_data()\n",
    "\n",
    "#Â Data is a dictionary with an entry for every subject. Have a look!\n",
    "# Each entry is itself a list, with the trial by trial data\n",
    "# on task difficulty, rection times, and trial error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3f6445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert this nested data to a (flat) dataframe containing all data.\n",
    "# (Hint: you can create a DataFrame for every subject and then concatenate) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c01fd768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the data for subject 0, and create a scatter plot \n",
    "# with the reaction time as a function of the trial difficulty level\n",
    "# (Hint: remember the dataframe.plot() function from last lecture)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77864f09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>handedness</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>subject_0</th>\n",
       "      <td>F</td>\n",
       "      <td>left</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject_1</th>\n",
       "      <td>M</td>\n",
       "      <td>right</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject_2</th>\n",
       "      <td>F</td>\n",
       "      <td>left</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject_3</th>\n",
       "      <td>F</td>\n",
       "      <td>right</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject_4</th>\n",
       "      <td>F</td>\n",
       "      <td>left</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sex handedness  age\n",
       "subject_0   F       left   37\n",
       "subject_1   M      right   31\n",
       "subject_2   F       left   21\n",
       "subject_3   F      right   29\n",
       "subject_4   F       left   23"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the subjects dataframe from the csv file at the url:\n",
    "# https://raw.githubusercontent.com/vigji/python-cimec/main/practicals/data/subjects_df.csv\n",
    "\n",
    "subject_df = pd.read_csv(\"https://raw.githubusercontent.com/vigji/python-cimec/main/practicals/data/subjects_df.csv\",\n",
    "                         index_col=0)\n",
    "subject_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a1d632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now use boolean indexing on the subject dataframe to include only left-handed males \n",
    "# above 30 years in the analysis.\n",
    "# Plot the reaction time as a function of the trial difficulty \n",
    "# level for this subpopulation only:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b8fcace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Allen Brain Observatory dataset (https://allensdk.readthedocs.io/en/latest/visual_coding_neuropixels.html)\n",
    "# contains electrophysiology data (single neuron activity) from hundreds of\n",
    "# recording sessions in the visual cortex of mice.\n",
    "\n",
    "# Here you find some of their data:\n",
    "\n",
    "# - a neuron_csv with information about individual neurons from all electrodes from all sessions\n",
    "#   Each neuron has a channel_id column that specifies which electrode it was recorded from\n",
    "\n",
    "# - A channel_csv with information about individual electrodes from all sessions.\n",
    "#   Each channel has a session_id that specifies from whifh session it was recorded\n",
    "\n",
    "# - A session_csv with information about all sessions and the animal that was recorded \n",
    "#   in that session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044670a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataframes. Then"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08e3124",
   "metadata": {},
   "source": [
    "#### 1.4.1  `.groupby()` and index broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e12fcc4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-22T07:35:32.752413Z",
     "start_time": "2023-05-22T07:35:32.296106Z"
    }
   },
   "outputs": [],
   "source": [
    "# Take the meteo dataset using the function below\n",
    "def get_meteo_dataset():\n",
    "    \"\"\"Get a meteo dataset from the open-meteo API using a fixed window.\n",
    "    Note how easy it is to get data from the web with pandas! As long as we give the URL of the csv data, pandas can read it.\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    # URL = \"https://api.open-meteo.com/v1/forecast?latitude=52.52&longitude=13.41&current=temperature_2m,relativehumidity_2m,precipitation,windspeed_10m,winddirection_10m&start_date=2023-02-10&end_date=2023-05-28&format=csv\"\n",
    "    URL = \"https://api.open-meteo.com/v1/forecast?latitude=52.52&longitude=13.41&current=temperature_2m,wind_speed_10m&hourly=temperature_2m,relative_humidity_2m,precipitation,wind_speed_10m,winddirection_10m&start_date=2024-04-01&end_date=2024-04-20&format=csv\"\n",
    "    df = pd.read_csv(URL, skiprows=6)  # read the csv file, skipping the first 3 rows (a header)\n",
    "    df.columns = [col.split(\" \")[0] for col in df.columns]  # simplify column names\n",
    "    df[\"time\"] = pd.to_datetime(df[\"time\"])  # convert the time column to datetime\n",
    "    df[\"hour\"], df[\"dayofyear\"] = df[\"time\"].dt.hour, df[\"time\"].dt.dayofyear  # extract the hour and day of year\n",
    "\n",
    "    # Here we artificially corrupt some of the data:\n",
    "    missing_idx = np.random.choice(df.index[:1000], 100)\n",
    "    df.loc[missing_idx, :] = np.nan\n",
    "    return df\n",
    "\n",
    "# This new meteo dataset has columns for the day of the year, \n",
    "# hour of the day, and day of the week.\n",
    "# Check out the data and make sure we don't have missing values!\n",
    "ds = get_meteo_dataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e6eebe25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-22T07:35:39.971697Z",
     "start_time": "2023-05-22T07:35:39.961574Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use the .groupby() method to compute the mean temperature for each hour of the day:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b981630b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using pandas index broadcasting, subtract from each day of the year \n",
    "# its average temperature, and plot the result to check if it makes sense.\n",
    "# (Hint: you will have to set a new index to the dataframe \n",
    "# for the broadcasting to work):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89443646",
   "metadata": {},
   "source": [
    "#### 1.4.2 `.rolling()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4cb9f4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-22T08:23:06.492706Z",
     "start_time": "2023-05-22T08:23:06.407328Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute the maximum and the minimum of the temperature using a rolling window of 24 samples.\n",
    "# Plot the original curve and the smoothed one to check what you did:\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course-env",
   "language": "python",
   "name": "course-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
